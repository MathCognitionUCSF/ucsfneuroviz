{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from nilearn import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import image\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "from nilearn import plotting\n",
    "from nilearn.glm import threshold_stats_img\n",
    "from nilearn.glm.first_level import make_first_level_design_matrix\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data by entering the local path\n",
    "root = ''\n",
    "func_data_run_1 = glob.glob(root + 'sub-*/ses-*/func/*_run-1*desc-preproc_bold.nii.gz')\n",
    "func_data_run_2 = glob.glob(root + 'sub-*/ses-*/func/*_run-2*desc-preproc_bold.nii.gz')\n",
    "subj_T1 = glob.glob(root + 'sub-*/ses-*/anat/*space-*preproc_T1w.nii.gz') #pick a specific T1 for background image\n",
    "\n",
    "# Define some params\n",
    "nr_sub = 1\n",
    "n_scans = 188 #total = 564 / 3 = 188 (e1, e2, e3)\n",
    "tr = 1.63 #how much time it takes to acquire 1 volume\n",
    "nr_cond = 7 #words, faces, numbers, places, objects, bodies, baseline\n",
    "epoch_duration = 6.0 # in sec\n",
    "nr_cont_gp = 16 \n",
    "\n",
    "\n",
    "# Get the confounds file\n",
    "conf_data_run_1 = glob.glob(root + 'sub-*/ses-*/func/*_run-1_desc-confounds_timeseries.tsv')\n",
    "conf_data_run_2 = glob.glob(root + 'sub-*/ses-*/func/*_run-2_desc-confounds_timeseries.tsv')\n",
    "\n",
    "# Create a list of dataframes with motion confounds and framewise disp\n",
    "motion_conf_all=[]\n",
    "for n in range(nr_sub):\n",
    "    temp_df = pd.read_csv(conf_data_run_1[n], delimiter='\\t')\n",
    "    temp_df_2 = pd.read_csv(conf_data_run_2[n], delimiter='\\t')\n",
    "    sub_motion_params_1 = pd.DataFrame(temp_df, columns=['trans_x', 'trans_y', 'trans_z', 'rot_x', 'rot_y', 'rot_z', 'framewise_displacement'])\n",
    "    sub_motion_params_1['framewise_displacement'][0] = 0 # Change the first elem to 0 from Nan\n",
    "    sub_motion_params_2 = pd.DataFrame(temp_df_2, columns=['trans_x', 'trans_y', 'trans_z', 'rot_x', 'rot_y', 'rot_z', 'framewise_displacement'])\n",
    "    sub_motion_params_2['framewise_displacement'][0] = 0 # Change the first elem to 0 from Nan\n",
    "    motion_conf_all.append([sub_motion_params_1, sub_motion_params_2])\n",
    "\n",
    "\n",
    "# Get the event onsets\n",
    "onsets_dir = root + 'sub-control_task-floc_run-1_events.tsv'\n",
    "events_allsub = []\n",
    "for n in range(nr_sub):\n",
    "    events_df = pd.read_csv(onsets_dir, sep='\\t')\n",
    "    events_allsub.append([events_df, events_df]) #nr_sub multiply events for all sub\n",
    "\n",
    "#Concatenate run-1 and run-2 for each patient\n",
    "func_data=[]\n",
    "for n in range(nr_sub):\n",
    "    func_data.append([image.concat_imgs(func_data_run_1[n], auto_resample=False), image.concat_imgs(func_data_run_2[n], auto_resample=False)])\n",
    "\n",
    "# Smoothing\n",
    "func_data_sm = [] \n",
    "for n in range(nr_sub):\n",
    "    func_data_sm.append(image.smooth_img(func_data[n], fwhm=4))\n",
    "\n",
    "frame_times = np.arange(n_scans) * tr\n",
    "design_matrices = []\n",
    "for n in range(nr_sub):\n",
    "    design_matrices.append([make_first_level_design_matrix(frame_times, events=events_df, hrf_model='spm'), make_first_level_design_matrix(frame_times, events=events_df, hrf_model='spm')])\n",
    "\n",
    "# contrast matrix\n",
    "contrast_matrix = np.eye(design_matrices[0][0].shape[1]) #double because its nested\n",
    "contrasts = dict([(column, contrast_matrix[i])\n",
    "                  for i, column in enumerate(design_matrices[0][0].columns)])\n",
    "design_matrix = design_matrices[0][0].reset_index()\n",
    "\n",
    "fmri_glm_single_subj = FirstLevelModel(tr, noise_model='ar1', standardize=False, hrf_model=hrf_model)\n",
    "fmri_glm_single_subj = fmri_glm_single_subj.fit(func_data_sm[0], events= events_allsub[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_interactive_floc(glm, subj_id, root, alpha):\n",
    "\n",
    "    #need to set specific contrasts?? and generate all html versions?\n",
    "    contrast = (contrasts['Faces'], contrasts['Faces'])\n",
    "    test_contrast = {\"faces-oth\": contrast}\n",
    "\n",
    "    subj_T1 = glob.glob(root + f'sub-{subj_id}/ses-*/anat/*space-*preproc_T1w.nii.gz') #pick a specific T1 for background image\n",
    "    subj_T1_img = image.load_img(subj_T1)\n",
    "\n",
    "    for contrast_id, contrast_val in test_contrast.items():\n",
    "            z_map = glm.compute_contrast(contrast_val, output_type='z_score')\n",
    "            z_img_thresh, thresholded = threshold_stats_img(z_map, alpha=alpha, height_control=\"fpr\", cluster_threshold=20, two_sided = False)\n",
    "    view = plotting.view_img(\n",
    "        z_img_thresh,\n",
    "        colorbar=True,\n",
    "        bg_img=subj_T1_img,\n",
    "        cut_coords=[-45, -57, -12])\n",
    "   \n",
    "    view.save_as_html(f'{subj_id}_alpha{alpha}_interactive_floc.html') #add path to where we want to save floc.html here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm = fmri_glm_single_subj\n",
    "subj_id = '1234'\n",
    "root = ''\n",
    "alpha_list = [0.001, 0.01, 0.05]\n",
    "\n",
    "for alpha in alpha_list:\n",
    "    plot_interactive_floc(glm, subj_id, root, alpha)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7d7010f9d425683ae41e5b0b8dc0d6eb35e44e03f18d381e022146c22a330439"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
